{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Thoughts About CheXNet — And The Way Human Performance Should (And Should Not) Be Measured\n",
    "\n",
    "Written by Bálint Botz, original article can be found [here](https://medium.com/@BalintBotz/a-few-thoughts-about-chexnet-and-the-way-human-performance-should-and-should-not-be-measured-68031dca7bf)\n",
    "\n",
    "- __Is 'soft' ground truth really the ground truth?__\n",
    "    - dataset used for training algorithm -- `ChestX-ray8` -- extracted from radiology reports via text mining\n",
    "        - in essence, one radiologist's judgement\n",
    "    - Substantially different pathologies can be very similar in x-rays\n",
    "        - ground truth of original data set arguable at best\n",
    "        \n",
    "- __The devil is in the details (of the medical record)__\n",
    "    - radiologists in study did not have access to patient information\n",
    "        - non-existent scenario in clinical practice\n",
    "    - have acess to all clinical information, including lab results\n",
    "        - helps to narrow down diagnostic possibilities\n",
    "        - helps to produce useful report (instead of vague hedging)\n",
    "        \n",
    "- __The power of priors__\n",
    "    - prior examinations invaluable in radiology\n",
    "    - participants of CheXNet had to interpret all images with no priors\n",
    "        - therefore measures the low-end of human performance\n",
    "        \n",
    "- __Each armed with their own tools__\n",
    "    - Radiology reading room is unique environment\n",
    "        - designed to maximize sensitivity, with appropriate lighting, dedicated diagnostic monitors and other task-specific tools\n",
    "        - PACS system that allows for windowing, greyscale invert, and zooming of images\n",
    "    - test radiologists in this environment\n",
    "        - in this study, had to interpret images that were distorted, downsized, and cropped to meet needs of algorithm\n",
    "\n",
    "- __A frontal chest x-ray is only the begining__\n",
    "    - the lateral view is often utilized as an immensely useful ancillary technique\n",
    "        - in conjuction with frontal view, helps clear up localization and etiology of abnormalities identified from frontal radiograph\n",
    "        \n",
    "- __Summary__\n",
    "    - drawbacks were hidden deep in article\n",
    "        - will not receive same attention as 'AI beats doctors' headline\n",
    "    - potential problem when comparing human v. machine:\n",
    "        - little if any effort put into mimicking actual radiological workflow\n",
    "    - runs risk of limitations and shortcomings painfully apparent for professionals not receiving any attention\n",
    "    - CheXNet holds great promise\n",
    "        - just not ready for being deployed 'in the wild'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the ChestXray14 dataset: problems\n",
    "\n",
    "Written by Luke Oakden-Rayner, original blog post can be found [here](https://lukeoakdenrayner.wordpress.com/2017/12/18/the-chestxray14-dataset-problems/)\n",
    "\n",
    "- Upfront, ChestXray14 dataset, is __not fit__ for training medical AI systems to do diagnostic work\n",
    "- Specific problems:\n",
    "    - label accuracy\n",
    "    - what labels actually mean, medically\n",
    "    - usefullness of labels for image analysis\n",
    "- opinion: [paper](https://arxiv.org/abs/1705.02315) should have spent more time explaining the dataset\n",
    "    - many of the data users will be computer scientists w/o clinical knowledge\n",
    "        - lack awareness of potential pitfalls\n",
    "    - [paper](https://arxiv.org/abs/1705.02315) describes text mining and computer vision tasks\n",
    "    \n",
    "__Always look at the images__\n",
    "\n",
    "- Oakden-Rayner personally looked at the images\n",
    "    - he is a radiologist\n",
    "- NIH team do not state that they reviewed the images\n",
    "    - judged performance of their image labeling process by testing whether the labels matched their report text\n",
    "- There are ways to build image labels w/o images\n",
    "    - ICD codes, extract them from reports, can use follow-up data\n",
    "    - 100% necessary though to look at the images\n",
    "    - Looking at images is sanity check for radiology\n",
    "- Advises to set aside a small random subset for each class, ~100-200 images\n",
    "    - just has to be a rough check\n",
    "    - if you don't look at images, things can go bad...\n",
    "    \n",
    "__Part 1: Visual label accuracy in ChestXray14__\n",
    "\n",
    "- Oakden-Rayner reviewed ~130 images in each class\n",
    "    - does express that they are not perfect\n",
    "    - __however__... his results are vastly different than the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CheXNet: an in-depth review\n",
    "\n",
    "Written by Luke Oakden-Rayner, original blog post can be found [here](https://lukeoakdenrayner.wordpress.com/2018/01/24/chexnet-an-in-depth-review/)\n",
    "\n",
    "- Stanford's [CheXNet](https://arxiv.org/abs/1711.05225) claimed it had developed \"an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists\"\n",
    "    - this is a __BIG__ claim\n",
    "- Pranav Rajpurkar has been really receptive to criticism (which should be the norm for scientific communication)\n",
    "\n",
    "__A CheXNet? What's a CheXNet?__\n",
    "\n",
    "- type of image analysing AI called a _DenseNet_\n",
    "    - a variant of a _ConvNet_ & similar to a _ResNet_\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
